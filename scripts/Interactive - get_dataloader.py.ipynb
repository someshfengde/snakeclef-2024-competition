{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m/teamspace/studios/this_studio/scripts/get_dataloader.py:17\u001b[0m\n\u001b[1;32m      7\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mrename({\u001b[39m\"\u001b[39m\u001b[39mclass_id\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m      9\u001b[0m datablock \u001b[39m=\u001b[39m DataBlock(\n\u001b[1;32m     10\u001b[0m     blocks\u001b[39m=\u001b[39m(ImageBlock, CategoryBlock),  \u001b[39m# Define the type of input and output blocks\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     get_x\u001b[39m=\u001b[39mColReader(\u001b[39m'\u001b[39m\u001b[39mimage_path\u001b[39m\u001b[39m'\u001b[39m),       \u001b[39m# Function to get the image files\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     item_tfms\u001b[39m=\u001b[39mResize(\u001b[39m224\u001b[39m)                \u001b[39m# Resize images to 224x224 pixels\u001b[39;00m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m dls \u001b[39m=\u001b[39m datablock\u001b[39m.\u001b[39;49mdataloaders(df)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/data/block.py:155\u001b[0m, in \u001b[0;36mDataBlock.dataloaders\u001b[0;34m(self, source, path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdataloaders\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[1;32m    150\u001b[0m     source, \u001b[39m# The data source\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     path:\u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m# Data source and default `Learner` path \u001b[39;00m\n\u001b[1;32m    152\u001b[0m     verbose:\u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m# Show verbose messages\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    154\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataLoaders:\n\u001b[0;32m--> 155\u001b[0m     dsets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatasets(source, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    156\u001b[0m     kwargs \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, \u001b[39m'\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m'\u001b[39m: verbose}\n\u001b[1;32m    157\u001b[0m     \u001b[39mreturn\u001b[39;00m dsets\u001b[39m.\u001b[39mdataloaders(path\u001b[39m=\u001b[39mpath, after_item\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_tfms, after_batch\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_tfms, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/data/block.py:147\u001b[0m, in \u001b[0;36mDataBlock.datasets\u001b[0;34m(self, source, verbose)\u001b[0m\n\u001b[1;32m    145\u001b[0m splits \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplitter \u001b[39mor\u001b[39;00m RandomSplitter())(items)\n\u001b[1;32m    146\u001b[0m pv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(splits)\u001b[39m}\u001b[39;00m\u001b[39m datasets of sizes \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(s))\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39ms\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39msplits])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, verbose)\n\u001b[0;32m--> 147\u001b[0m \u001b[39mreturn\u001b[39;00m Datasets(items, tfms\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_combine_type_tfms(), splits\u001b[39m=\u001b[39;49msplits, dl_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdl_type, n_inp\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_inp, verbose\u001b[39m=\u001b[39;49mverbose)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/data/core.py:443\u001b[0m, in \u001b[0;36mDatasets.__init__\u001b[0;34m(self, items, tfms, tls, n_inp, dl_type, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[1;32m    435\u001b[0m     items:\u001b[39mlist\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m# List of items to create `Datasets`\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     tfms:MutableSequence\u001b[39m|\u001b[39mPipeline\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m# List of `Transform`(s) or `Pipeline` to apply\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    441\u001b[0m ):\n\u001b[1;32m    442\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(dl_type\u001b[39m=\u001b[39mdl_type)\n\u001b[0;32m--> 443\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtls \u001b[39m=\u001b[39m L(tls \u001b[39mif\u001b[39;00m tls \u001b[39melse\u001b[39;00m [TfmdLists(items, t, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m L(ifnone(tfms,[\u001b[39mNone\u001b[39;00m]))])\n\u001b[1;32m    444\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_inp \u001b[39m=\u001b[39m ifnone(n_inp, \u001b[39mmax\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtls)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/data/core.py:443\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[1;32m    435\u001b[0m     items:\u001b[39mlist\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m# List of items to create `Datasets`\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     tfms:MutableSequence\u001b[39m|\u001b[39mPipeline\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m# List of `Transform`(s) or `Pipeline` to apply\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    441\u001b[0m ):\n\u001b[1;32m    442\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(dl_type\u001b[39m=\u001b[39mdl_type)\n\u001b[0;32m--> 443\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtls \u001b[39m=\u001b[39m L(tls \u001b[39mif\u001b[39;00m tls \u001b[39melse\u001b[39;00m [TfmdLists(items, t, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m L(ifnone(tfms,[\u001b[39mNone\u001b[39;00m]))])\n\u001b[1;32m    444\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_inp \u001b[39m=\u001b[39m ifnone(n_inp, \u001b[39mmax\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtls)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastcore/foundation.py:98\u001b[0m, in \u001b[0;36m_L_Meta.__call__\u001b[0;34m(cls, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(x,\u001b[39mcls\u001b[39m): \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/data/core.py:357\u001b[0m, in \u001b[0;36mTfmdLists.__init__\u001b[0;34m(self, items, tfms, use_list, do_setup, split_idx, train_setup, splits, types, verbose, dl_type)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39mif\u001b[39;00m do_setup:\n\u001b[1;32m    356\u001b[0m     pv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSetting up \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtfms\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, verbose)\n\u001b[0;32m--> 357\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup(train_setup\u001b[39m=\u001b[39;49mtrain_setup)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/data/core.py:378\u001b[0m, in \u001b[0;36mTfmdLists.setup\u001b[0;34m(self, train_setup)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[1;32m    376\u001b[0m     train_setup:\u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m \u001b[39m# Apply `Transform`(s) only on training `DataLoader`\u001b[39;00m\n\u001b[1;32m    377\u001b[0m ):\n\u001b[0;32m--> 378\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtfms\u001b[39m.\u001b[39;49msetup(\u001b[39mself\u001b[39;49m, train_setup)\n\u001b[1;32m    379\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    380\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(\u001b[39m0\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplits \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplits[\u001b[39m0\u001b[39m])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastcore/transform.py:200\u001b[0m, in \u001b[0;36mPipeline.setup\u001b[0;34m(self, items, train_setup)\u001b[0m\n\u001b[1;32m    198\u001b[0m tfms \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs[:]\n\u001b[1;32m    199\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs\u001b[39m.\u001b[39mclear()\n\u001b[0;32m--> 200\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tfms: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd(t,items, train_setup)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastcore/transform.py:204\u001b[0m, in \u001b[0;36mPipeline.add\u001b[0;34m(self, ts, items, train_setup)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd\u001b[39m(\u001b[39mself\u001b[39m,ts, items\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, train_setup\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_listy(ts): ts\u001b[39m=\u001b[39m[ts]\n\u001b[0;32m--> 204\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ts: t\u001b[39m.\u001b[39;49msetup(items, train_setup)\n\u001b[1;32m    205\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mts\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs\u001b[39m.\u001b[39msorted(key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39morder\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastcore/transform.py:87\u001b[0m, in \u001b[0;36mTransform.setup\u001b[0;34m(self, items, train_setup)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(\u001b[39mself\u001b[39m, items\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, train_setup\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     86\u001b[0m     train_setup \u001b[39m=\u001b[39m train_setup \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_setup \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_setup\n\u001b[0;32m---> 87\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetups(\u001b[39mgetattr\u001b[39;49m(items, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, items) \u001b[39mif\u001b[39;49;00m train_setup \u001b[39melse\u001b[39;49;00m items)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastcore/dispatch.py:120\u001b[0m, in \u001b[0;36mTypeDispatch.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minst \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: f \u001b[39m=\u001b[39m MethodType(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minst)\n\u001b[1;32m    119\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mowner \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: f \u001b[39m=\u001b[39m MethodType(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mowner)\n\u001b[0;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/data/transforms.py:256\u001b[0m, in \u001b[0;36mCategorize.setups\u001b[0;34m(self, dsets)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetups\u001b[39m(\u001b[39mself\u001b[39m, dsets):\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m dsets \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab \u001b[39m=\u001b[39m CategoryMap(dsets, sort\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msort, add_na\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_na)\n\u001b[1;32m    257\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/data/transforms.py:232\u001b[0m, in \u001b[0;36mCategoryMap.__init__\u001b[0;34m(self, col, sort, add_na, strict)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(col,\u001b[39m'\u001b[39m\u001b[39munique\u001b[39m\u001b[39m'\u001b[39m): col \u001b[39m=\u001b[39m L(col, use_list\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    231\u001b[0m     \u001b[39m# `o==o` is the generalized definition of non-NaN used by Pandas\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m     items \u001b[39m=\u001b[39m L(o \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m col\u001b[39m.\u001b[39;49munique() \u001b[39mif\u001b[39;00m o\u001b[39m==\u001b[39mo)\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m sort: items \u001b[39m=\u001b[39m items\u001b[39m.\u001b[39msorted()\n\u001b[1;32m    234\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m#na#\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m items \u001b[39mif\u001b[39;00m add_na \u001b[39melse\u001b[39;00m items\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastcore/foundation.py:166\u001b[0m, in \u001b[0;36mL.unique\u001b[0;34m(self, sort, bidir, start)\u001b[0m\n\u001b[0;32m--> 166\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munique\u001b[39m(\u001b[39mself\u001b[39m, sort\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, bidir\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, start\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m): \u001b[39mreturn\u001b[39;00m L(uniqueify(\u001b[39mself\u001b[39;49m, sort\u001b[39m=\u001b[39;49msort, bidir\u001b[39m=\u001b[39;49mbidir, start\u001b[39m=\u001b[39;49mstart))\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastcore/basics.py:724\u001b[0m, in \u001b[0;36muniqueify\u001b[0;34m(x, sort, bidir, start)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39muniqueify\u001b[39m(x, sort\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, bidir\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, start\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    723\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mUnique elements in `x`, optional `sort`, optional return reverse correspondence, optional prepend with elements.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 724\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mdict\u001b[39;49m\u001b[39m.\u001b[39;49mfromkeys(x))\n\u001b[1;32m    725\u001b[0m     \u001b[39mif\u001b[39;00m start \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: res \u001b[39m=\u001b[39m listify(start)\u001b[39m+\u001b[39mres\n\u001b[1;32m    726\u001b[0m     \u001b[39mif\u001b[39;00m sort: res\u001b[39m.\u001b[39msort()\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/data/core.py:368\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m--> 368\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m): \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39;49m[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)))\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/data/core.py:406\u001b[0m, in \u001b[0;36mTfmdLists.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    404\u001b[0m res \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(idx)\n\u001b[1;32m    405\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_item \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m--> 406\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_after_item(res) \u001b[39mif\u001b[39;00m is_indexer(idx) \u001b[39melse\u001b[39;00m res\u001b[39m.\u001b[39mmap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_item)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/data/core.py:366\u001b[0m, in \u001b[0;36mTfmdLists._after_item\u001b[0;34m(self, o)\u001b[0m\n\u001b[0;32m--> 366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_after_item\u001b[39m(\u001b[39mself\u001b[39m, o): \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtfms(o)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastcore/transform.py:208\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, o)\u001b[0m\n\u001b[0;32m--> 208\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, o): \u001b[39mreturn\u001b[39;00m compose_tfms(o, tfms\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfs, split_idx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplit_idx)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastcore/transform.py:158\u001b[0m, in \u001b[0;36mcompose_tfms\u001b[0;34m(x, tfms, is_enc, reverse, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m tfms:\n\u001b[1;32m    157\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_enc: f \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mdecode\n\u001b[0;32m--> 158\u001b[0m     x \u001b[39m=\u001b[39m f(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    159\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/data/transforms.py:218\u001b[0m, in \u001b[0;36mColReader.__call__\u001b[0;34m(self, o, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, o, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 218\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcols) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_one(o, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcols[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    219\u001b[0m     \u001b[39mreturn\u001b[39;00m L(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_one(o, c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcols)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/data/transforms.py:212\u001b[0m, in \u001b[0;36mColReader._do_one\u001b[0;34m(self, r, c)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_one\u001b[39m(\u001b[39mself\u001b[39m, r, c):\n\u001b[0;32m--> 212\u001b[0m     o \u001b[39m=\u001b[39m r[c] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(c, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mgetattr\u001b[39m(r, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m, []) \u001b[39melse\u001b[39;00m \u001b[39mgetattr\u001b[39m(r, c)\n\u001b[1;32m    213\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpref)\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuff)\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_delim \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mreturn\u001b[39;00m o\n\u001b[1;32m    214\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_delim \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpref\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mo\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuff\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1123\u001b[0m \u001b[39m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[39m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1239\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/folds/fold_0.csv\")\n",
    "df = df.rename({\"class_id\":\"label\"})\n",
    "\n",
    "datablock = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),  # Define the type of input and output blocks\n",
    "    get_x=ColReader('image_path'),       # Function to get the image files\n",
    "    get_y=ColReader('label'),            # Function to get the labels\n",
    "    splitter=RandomSplitter(valid_pct=0.2),  # Split data into training and validation sets\n",
    "    item_tfms=Resize(224)                # Resize images to 224x224 pixels\n",
    ")\n",
    "\n",
    "dls = datablock.dataloaders(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_id</th>\n",
       "      <th>endemic</th>\n",
       "      <th>binomial_name</th>\n",
       "      <th>code</th>\n",
       "      <th>image_path</th>\n",
       "      <th>class_id</th>\n",
       "      <th>subset</th>\n",
       "      <th>captive</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36615943</td>\n",
       "      <td>False</td>\n",
       "      <td>Elaphe schrenckii</td>\n",
       "      <td>RU</td>\n",
       "      <td>data/SnakeCLEF2023-small_size/1990/Elaphe_schrenckii/57902708.jpg</td>\n",
       "      <td>621</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4527578</td>\n",
       "      <td>False</td>\n",
       "      <td>Naja nigricollis</td>\n",
       "      <td>TZ</td>\n",
       "      <td>data/SnakeCLEF2023-small_size/1991/Naja_nigricollis/5483474.jpg</td>\n",
       "      <td>1118</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125281</td>\n",
       "      <td>False</td>\n",
       "      <td>Psammophylax tritaeniatus</td>\n",
       "      <td>unknown</td>\n",
       "      <td>data/SnakeCLEF2023-small_size/1992/Psammophylax_tritaeniatus/177360.JPG</td>\n",
       "      <td>1359</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2621175</td>\n",
       "      <td>False</td>\n",
       "      <td>Eunectes murinus</td>\n",
       "      <td>VE</td>\n",
       "      <td>data/SnakeCLEF2023-small_size/1993/Eunectes_murinus/2934002.jpg</td>\n",
       "      <td>694</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1213449</td>\n",
       "      <td>False</td>\n",
       "      <td>Platyceps rhodorachis</td>\n",
       "      <td>JO</td>\n",
       "      <td>data/SnakeCLEF2023-small_size/1994/Platyceps_rhodorachis/1531786.JPG</td>\n",
       "      <td>1305</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18222</th>\n",
       "      <td>HM 78791</td>\n",
       "      <td>False</td>\n",
       "      <td>Xenochrophis maculatus</td>\n",
       "      <td>MY</td>\n",
       "      <td>data/HMP/Xenochrophis_maculatus/112613.jpg</td>\n",
       "      <td>1755</td>\n",
       "      <td>train-hm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18223</th>\n",
       "      <td>HM 298226</td>\n",
       "      <td>False</td>\n",
       "      <td>Platyceps collaris</td>\n",
       "      <td>LB</td>\n",
       "      <td>data/HMP/Platyceps_collaris/410337.jpg</td>\n",
       "      <td>1300</td>\n",
       "      <td>train-hm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18224</th>\n",
       "      <td>HM 336684</td>\n",
       "      <td>False</td>\n",
       "      <td>Lygophis dilepis</td>\n",
       "      <td>PY</td>\n",
       "      <td>data/HMP/Lygophis_dilepis/464639.jpg</td>\n",
       "      <td>986</td>\n",
       "      <td>train-hm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18225</th>\n",
       "      <td>HM 291719</td>\n",
       "      <td>True</td>\n",
       "      <td>Cryptophis pallidiceps</td>\n",
       "      <td>AU</td>\n",
       "      <td>data/HMP/Cryptophis_pallidiceps/403081.jpg</td>\n",
       "      <td>450</td>\n",
       "      <td>train-hm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18226</th>\n",
       "      <td>HM 337362</td>\n",
       "      <td>False</td>\n",
       "      <td>Oxybelis vittatus</td>\n",
       "      <td>PA</td>\n",
       "      <td>data/HMP/Oxybelis_vittatus/463861.jpg</td>\n",
       "      <td>1213</td>\n",
       "      <td>train-hm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18227 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      observation_id  endemic              binomial_name     code  \\\n",
       "0           36615943    False          Elaphe schrenckii       RU   \n",
       "1            4527578    False           Naja nigricollis       TZ   \n",
       "2             125281    False  Psammophylax tritaeniatus  unknown   \n",
       "3            2621175    False           Eunectes murinus       VE   \n",
       "4            1213449    False      Platyceps rhodorachis       JO   \n",
       "...              ...      ...                        ...      ...   \n",
       "18222       HM 78791    False     Xenochrophis maculatus       MY   \n",
       "18223      HM 298226    False         Platyceps collaris       LB   \n",
       "18224      HM 336684    False           Lygophis dilepis       PY   \n",
       "18225      HM 291719     True     Cryptophis pallidiceps       AU   \n",
       "18226      HM 337362    False          Oxybelis vittatus       PA   \n",
       "\n",
       "                                                                    image_path  \\\n",
       "0            data/SnakeCLEF2023-small_size/1990/Elaphe_schrenckii/57902708.jpg   \n",
       "1              data/SnakeCLEF2023-small_size/1991/Naja_nigricollis/5483474.jpg   \n",
       "2      data/SnakeCLEF2023-small_size/1992/Psammophylax_tritaeniatus/177360.JPG   \n",
       "3              data/SnakeCLEF2023-small_size/1993/Eunectes_murinus/2934002.jpg   \n",
       "4         data/SnakeCLEF2023-small_size/1994/Platyceps_rhodorachis/1531786.JPG   \n",
       "...                                                                        ...   \n",
       "18222                               data/HMP/Xenochrophis_maculatus/112613.jpg   \n",
       "18223                                   data/HMP/Platyceps_collaris/410337.jpg   \n",
       "18224                                     data/HMP/Lygophis_dilepis/464639.jpg   \n",
       "18225                               data/HMP/Cryptophis_pallidiceps/403081.jpg   \n",
       "18226                                    data/HMP/Oxybelis_vittatus/463861.jpg   \n",
       "\n",
       "       class_id    subset captive  kfold  \n",
       "0           621     train     NaN      0  \n",
       "1          1118     train     NaN      0  \n",
       "2          1359     train     NaN      0  \n",
       "3           694     train     NaN      0  \n",
       "4          1305     train     NaN      0  \n",
       "...         ...       ...     ...    ...  \n",
       "18222      1755  train-hm     NaN      0  \n",
       "18223      1300  train-hm     NaN      0  \n",
       "18224       986  train-hm     NaN      0  \n",
       "18225       450  train-hm     NaN      0  \n",
       "18226      1213  train-hm     NaN      0  \n",
       "\n",
       "[18227 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/folds/fold_0.csv\")\n",
    "df = df.rename({\"class_id\":\"label\"}, axis = 1)\n",
    "\n",
    "datablock = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),  # Define the type of input and output blocks\n",
    "    get_x=ColReader('image_path'),       # Function to get the image files\n",
    "    get_y=ColReader('label'),            # Function to get the labels\n",
    "    splitter=RandomSplitter(valid_pct=0.2),  # Split data into training and validation sets\n",
    "    item_tfms=Resize(224)                # Resize images to 224x224 pixels\n",
    ")\n",
    "\n",
    "dls = datablock.dataloaders(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.data.core.DataLoaders at 0x7fdb7c543b80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unknown model (mae_hiera_base_224)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m learn \u001b[39m=\u001b[39m vision_learner(dls, \u001b[39m\"\u001b[39;49m\u001b[39mmae_hiera_base_224\u001b[39;49m\u001b[39m\"\u001b[39;49m, metrics\u001b[39m=\u001b[39;49maccuracy)\n\u001b[1;32m      3\u001b[0m learn\u001b[39m.\u001b[39mfine_tune(\u001b[39m6\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:232\u001b[0m, in \u001b[0;36mvision_learner\u001b[0;34m(dls, arch, normalize, n_out, pretrained, weights, loss_func, opt_func, lr, splitter, cbs, metrics, path, model_dir, wd, wd_bn_bias, train_bn, moms, cut, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m n_in \u001b[39m=\u001b[39m kwargs[\u001b[39m'\u001b[39m\u001b[39mn_in\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mn_in\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m \u001b[39m3\u001b[39m\n\u001b[1;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arch, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 232\u001b[0m     model,cfg \u001b[39m=\u001b[39m create_timm_model(arch, n_out, default_split, pretrained, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_args)\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m normalize: _timm_norm(dls, cfg, pretrained, n_in)\n\u001b[1;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:191\u001b[0m, in \u001b[0;36mcreate_timm_model\u001b[0;34m(arch, n_out, cut, pretrained, n_in, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_timm_model\u001b[39m(arch, n_out, cut\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, n_in\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, init\u001b[39m=\u001b[39mnn\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39mkaiming_normal_, custom_head\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    189\u001b[0m                      concat_pool\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, pool\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, lin_ftrs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ps\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, first_bn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, bn_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, lin_first\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, y_range\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    190\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCreate custom architecture using `arch`, `n_in` and `n_out` from the `timm` library\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 191\u001b[0m     model \u001b[39m=\u001b[39m timm\u001b[39m.\u001b[39;49mcreate_model(arch, pretrained\u001b[39m=\u001b[39;49mpretrained, num_classes\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, in_chans\u001b[39m=\u001b[39;49mn_in, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    192\u001b[0m     body \u001b[39m=\u001b[39m TimmBody(model, pretrained, \u001b[39mNone\u001b[39;00m, n_in)\n\u001b[1;32m    193\u001b[0m     nf \u001b[39m=\u001b[39m body\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnum_features\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/_factory.py:113\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         pretrained_cfg \u001b[39m=\u001b[39m pretrained_tag\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_model(model_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mUnknown model (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m model_name)\n\u001b[1;32m    115\u001b[0m create_fn \u001b[39m=\u001b[39m model_entrypoint(model_name)\n\u001b[1;32m    116\u001b[0m \u001b[39mwith\u001b[39;00m set_layer_config(scriptable\u001b[39m=\u001b[39mscriptable, exportable\u001b[39m=\u001b[39mexportable, no_jit\u001b[39m=\u001b[39mno_jit):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unknown model (mae_hiera_base_224)"
     ]
    }
   ],
   "source": [
    "learn = vision_learner(dls, \"mae_hiera_base_224\", metrics=accuracy)\n",
    "learn.fine_tune(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unknown model (hiera)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m learn \u001b[39m=\u001b[39m vision_learner(dls, \u001b[39m\"\u001b[39;49m\u001b[39mhiera\u001b[39;49m\u001b[39m\"\u001b[39;49m, metrics\u001b[39m=\u001b[39;49maccuracy)\n\u001b[1;32m      3\u001b[0m learn\u001b[39m.\u001b[39mfine_tune(\u001b[39m6\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:232\u001b[0m, in \u001b[0;36mvision_learner\u001b[0;34m(dls, arch, normalize, n_out, pretrained, weights, loss_func, opt_func, lr, splitter, cbs, metrics, path, model_dir, wd, wd_bn_bias, train_bn, moms, cut, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m n_in \u001b[39m=\u001b[39m kwargs[\u001b[39m'\u001b[39m\u001b[39mn_in\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mn_in\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m \u001b[39m3\u001b[39m\n\u001b[1;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arch, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 232\u001b[0m     model,cfg \u001b[39m=\u001b[39m create_timm_model(arch, n_out, default_split, pretrained, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_args)\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m normalize: _timm_norm(dls, cfg, pretrained, n_in)\n\u001b[1;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:191\u001b[0m, in \u001b[0;36mcreate_timm_model\u001b[0;34m(arch, n_out, cut, pretrained, n_in, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_timm_model\u001b[39m(arch, n_out, cut\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, n_in\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, init\u001b[39m=\u001b[39mnn\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39mkaiming_normal_, custom_head\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    189\u001b[0m                      concat_pool\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, pool\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, lin_ftrs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ps\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, first_bn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, bn_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, lin_first\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, y_range\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    190\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCreate custom architecture using `arch`, `n_in` and `n_out` from the `timm` library\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 191\u001b[0m     model \u001b[39m=\u001b[39m timm\u001b[39m.\u001b[39;49mcreate_model(arch, pretrained\u001b[39m=\u001b[39;49mpretrained, num_classes\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, in_chans\u001b[39m=\u001b[39;49mn_in, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    192\u001b[0m     body \u001b[39m=\u001b[39m TimmBody(model, pretrained, \u001b[39mNone\u001b[39;00m, n_in)\n\u001b[1;32m    193\u001b[0m     nf \u001b[39m=\u001b[39m body\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnum_features\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/_factory.py:113\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         pretrained_cfg \u001b[39m=\u001b[39m pretrained_tag\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_model(model_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mUnknown model (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m model_name)\n\u001b[1;32m    115\u001b[0m create_fn \u001b[39m=\u001b[39m model_entrypoint(model_name)\n\u001b[1;32m    116\u001b[0m \u001b[39mwith\u001b[39;00m set_layer_config(scriptable\u001b[39m=\u001b[39mscriptable, exportable\u001b[39m=\u001b[39mexportable, no_jit\u001b[39m=\u001b[39mno_jit):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unknown model (hiera)"
     ]
    }
   ],
   "source": [
    "learn = vision_learner(dls, \"hiera\", metrics=accuracy)\n",
    "learn.fine_tune(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unknown model (hiera)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m learn \u001b[39m=\u001b[39m vision_learner(dls, \u001b[39m\"\u001b[39;49m\u001b[39mhiera\u001b[39;49m\u001b[39m\"\u001b[39;49m, metrics\u001b[39m=\u001b[39;49maccuracy)\n\u001b[1;32m      3\u001b[0m learn\u001b[39m.\u001b[39mfine_tune(\u001b[39m6\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:232\u001b[0m, in \u001b[0;36mvision_learner\u001b[0;34m(dls, arch, normalize, n_out, pretrained, weights, loss_func, opt_func, lr, splitter, cbs, metrics, path, model_dir, wd, wd_bn_bias, train_bn, moms, cut, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m n_in \u001b[39m=\u001b[39m kwargs[\u001b[39m'\u001b[39m\u001b[39mn_in\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mn_in\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m \u001b[39m3\u001b[39m\n\u001b[1;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arch, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 232\u001b[0m     model,cfg \u001b[39m=\u001b[39m create_timm_model(arch, n_out, default_split, pretrained, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_args)\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m normalize: _timm_norm(dls, cfg, pretrained, n_in)\n\u001b[1;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:191\u001b[0m, in \u001b[0;36mcreate_timm_model\u001b[0;34m(arch, n_out, cut, pretrained, n_in, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_timm_model\u001b[39m(arch, n_out, cut\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, n_in\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, init\u001b[39m=\u001b[39mnn\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39mkaiming_normal_, custom_head\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    189\u001b[0m                      concat_pool\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, pool\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, lin_ftrs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ps\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, first_bn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, bn_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, lin_first\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, y_range\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    190\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCreate custom architecture using `arch`, `n_in` and `n_out` from the `timm` library\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 191\u001b[0m     model \u001b[39m=\u001b[39m timm\u001b[39m.\u001b[39;49mcreate_model(arch, pretrained\u001b[39m=\u001b[39;49mpretrained, num_classes\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, in_chans\u001b[39m=\u001b[39;49mn_in, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    192\u001b[0m     body \u001b[39m=\u001b[39m TimmBody(model, pretrained, \u001b[39mNone\u001b[39;00m, n_in)\n\u001b[1;32m    193\u001b[0m     nf \u001b[39m=\u001b[39m body\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnum_features\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/_factory.py:113\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         pretrained_cfg \u001b[39m=\u001b[39m pretrained_tag\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_model(model_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mUnknown model (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m model_name)\n\u001b[1;32m    115\u001b[0m create_fn \u001b[39m=\u001b[39m model_entrypoint(model_name)\n\u001b[1;32m    116\u001b[0m \u001b[39mwith\u001b[39;00m set_layer_config(scriptable\u001b[39m=\u001b[39mscriptable, exportable\u001b[39m=\u001b[39mexportable, no_jit\u001b[39m=\u001b[39mno_jit):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unknown model (hiera)"
     ]
    }
   ],
   "source": [
    "learn = vision_learner(dls, \"hiera\", metrics=accuracy)\n",
    "learn.fine_tune(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m timm\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timm' is not defined"
     ]
    }
   ],
   "source": [
    "timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/hiera/zipball/main\" to /home/zeus/.cache/torch/hub/main.zip\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/hiera/mae_hiera_base_224.pth\" to /home/zeus/.cache/torch/hub/checkpoints/mae_hiera_base_224.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 900M/900M [00:28<00:00, 33.7MB/s] \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MaskedAutoencoderHiera.forward() got an unexpected keyword argument 'pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhub\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mfacebookresearch/hiera\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmae_hiera_base_224\u001b[39m\u001b[39m\"\u001b[39m, pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, checkpoint\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmae_in1k\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m learn \u001b[39m=\u001b[39m vision_learner(dls, model, metrics\u001b[39m=\u001b[39;49maccuracy)\n\u001b[1;32m      4\u001b[0m learn\u001b[39m.\u001b[39mfine_tune(\u001b[39m6\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:236\u001b[0m, in \u001b[0;36mvision_learner\u001b[0;34m(dls, arch, normalize, n_out, pretrained, weights, loss_func, opt_func, lr, splitter, cbs, metrics, path, model_dir, wd, wd_bn_bias, train_bn, moms, cut, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[39mif\u001b[39;00m normalize: _add_norm(dls, meta, pretrained, n_in)\n\u001b[0;32m--> 236\u001b[0m     model \u001b[39m=\u001b[39m create_vision_model(arch, n_out, pretrained\u001b[39m=\u001b[39;49mpretrained, weights\u001b[39m=\u001b[39;49mweights, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_args)\n\u001b[1;32m    238\u001b[0m splitter \u001b[39m=\u001b[39m ifnone(splitter, meta[\u001b[39m'\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    239\u001b[0m learn \u001b[39m=\u001b[39m Learner(dls\u001b[39m=\u001b[39mdls, model\u001b[39m=\u001b[39mmodel, loss_func\u001b[39m=\u001b[39mloss_func, opt_func\u001b[39m=\u001b[39mopt_func, lr\u001b[39m=\u001b[39mlr, splitter\u001b[39m=\u001b[39msplitter, cbs\u001b[39m=\u001b[39mcbs,\n\u001b[1;32m    240\u001b[0m                metrics\u001b[39m=\u001b[39mmetrics, path\u001b[39m=\u001b[39mpath, model_dir\u001b[39m=\u001b[39mmodel_dir, wd\u001b[39m=\u001b[39mwd, wd_bn_bias\u001b[39m=\u001b[39mwd_bn_bias, train_bn\u001b[39m=\u001b[39mtrain_bn, moms\u001b[39m=\u001b[39mmoms)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:172\u001b[0m, in \u001b[0;36mcreate_vision_model\u001b[0;34m(arch, n_out, pretrained, weights, cut, n_in, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range)\u001b[0m\n\u001b[1;32m    170\u001b[0m     model \u001b[39m=\u001b[39m arch(weights\u001b[39m=\u001b[39mmeta[\u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m (weights \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m pretrained) \u001b[39melse\u001b[39;00m weights)\n\u001b[1;32m    171\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     model \u001b[39m=\u001b[39m arch(pretrained\u001b[39m=\u001b[39;49mpretrained)\n\u001b[1;32m    173\u001b[0m body \u001b[39m=\u001b[39m create_body(model, n_in, pretrained, ifnone(cut, meta[\u001b[39m'\u001b[39m\u001b[39mcut\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m    174\u001b[0m nf \u001b[39m=\u001b[39m num_features_model(nn\u001b[39m.\u001b[39mSequential(\u001b[39m*\u001b[39mbody\u001b[39m.\u001b[39mchildren())) \u001b[39mif\u001b[39;00m custom_head \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: MaskedAutoencoderHiera.forward() got an unexpected keyword argument 'pretrained'"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"facebookresearch/hiera\", model=\"mae_hiera_base_224\", pretrained=True, checkpoint=\"mae_in1k\")\n",
    "learn = vision_learner(dls, model, metrics=accuracy)\n",
    "learn.fine_tune(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/zeus/.cache/torch/hub/facebookresearch_hiera_main\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/hiera/mae_hiera_tiny_224.pth\" to /home/zeus/.cache/torch/hub/checkpoints/mae_hiera_tiny_224.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 630M/630M [00:18<00:00, 35.1MB/s] \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MaskedAutoencoderHiera.forward() got an unexpected keyword argument 'pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhub\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mfacebookresearch/hiera\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmae_hiera_tiny_224\u001b[39m\u001b[39m\"\u001b[39m, pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, checkpoint\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmae_in1k\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m learn \u001b[39m=\u001b[39m vision_learner(dls, model, metrics\u001b[39m=\u001b[39;49maccuracy, pretrained \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      4\u001b[0m learn\u001b[39m.\u001b[39mfine_tune(\u001b[39m6\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:236\u001b[0m, in \u001b[0;36mvision_learner\u001b[0;34m(dls, arch, normalize, n_out, pretrained, weights, loss_func, opt_func, lr, splitter, cbs, metrics, path, model_dir, wd, wd_bn_bias, train_bn, moms, cut, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[39mif\u001b[39;00m normalize: _add_norm(dls, meta, pretrained, n_in)\n\u001b[0;32m--> 236\u001b[0m     model \u001b[39m=\u001b[39m create_vision_model(arch, n_out, pretrained\u001b[39m=\u001b[39;49mpretrained, weights\u001b[39m=\u001b[39;49mweights, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_args)\n\u001b[1;32m    238\u001b[0m splitter \u001b[39m=\u001b[39m ifnone(splitter, meta[\u001b[39m'\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    239\u001b[0m learn \u001b[39m=\u001b[39m Learner(dls\u001b[39m=\u001b[39mdls, model\u001b[39m=\u001b[39mmodel, loss_func\u001b[39m=\u001b[39mloss_func, opt_func\u001b[39m=\u001b[39mopt_func, lr\u001b[39m=\u001b[39mlr, splitter\u001b[39m=\u001b[39msplitter, cbs\u001b[39m=\u001b[39mcbs,\n\u001b[1;32m    240\u001b[0m                metrics\u001b[39m=\u001b[39mmetrics, path\u001b[39m=\u001b[39mpath, model_dir\u001b[39m=\u001b[39mmodel_dir, wd\u001b[39m=\u001b[39mwd, wd_bn_bias\u001b[39m=\u001b[39mwd_bn_bias, train_bn\u001b[39m=\u001b[39mtrain_bn, moms\u001b[39m=\u001b[39mmoms)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:172\u001b[0m, in \u001b[0;36mcreate_vision_model\u001b[0;34m(arch, n_out, pretrained, weights, cut, n_in, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range)\u001b[0m\n\u001b[1;32m    170\u001b[0m     model \u001b[39m=\u001b[39m arch(weights\u001b[39m=\u001b[39mmeta[\u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m (weights \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m pretrained) \u001b[39melse\u001b[39;00m weights)\n\u001b[1;32m    171\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     model \u001b[39m=\u001b[39m arch(pretrained\u001b[39m=\u001b[39;49mpretrained)\n\u001b[1;32m    173\u001b[0m body \u001b[39m=\u001b[39m create_body(model, n_in, pretrained, ifnone(cut, meta[\u001b[39m'\u001b[39m\u001b[39mcut\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m    174\u001b[0m nf \u001b[39m=\u001b[39m num_features_model(nn\u001b[39m.\u001b[39mSequential(\u001b[39m*\u001b[39mbody\u001b[39m.\u001b[39mchildren())) \u001b[39mif\u001b[39;00m custom_head \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: MaskedAutoencoderHiera.forward() got an unexpected keyword argument 'pretrained'"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"facebookresearch/hiera\", model=\"mae_hiera_tiny_224\", pretrained=True, checkpoint=\"mae_in1k\")\n",
    "learn = vision_learner(dls, model, metrics=accuracy, pretrained = False)\n",
    "learn.fine_tune(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/zeus/.cache/torch/hub/facebookresearch_hiera_main\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MaskedAutoencoderHiera.forward() got an unexpected keyword argument 'pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhub\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mfacebookresearch/hiera\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmae_hiera_tiny_224\u001b[39m\u001b[39m\"\u001b[39m, pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, checkpoint\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmae_in1k\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m learn \u001b[39m=\u001b[39m vision_learner(dls, model, metrics\u001b[39m=\u001b[39;49maccuracy, pretrained \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      4\u001b[0m learn\u001b[39m.\u001b[39mfine_tune(\u001b[39m6\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:236\u001b[0m, in \u001b[0;36mvision_learner\u001b[0;34m(dls, arch, normalize, n_out, pretrained, weights, loss_func, opt_func, lr, splitter, cbs, metrics, path, model_dir, wd, wd_bn_bias, train_bn, moms, cut, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[39mif\u001b[39;00m normalize: _add_norm(dls, meta, pretrained, n_in)\n\u001b[0;32m--> 236\u001b[0m     model \u001b[39m=\u001b[39m create_vision_model(arch, n_out, pretrained\u001b[39m=\u001b[39;49mpretrained, weights\u001b[39m=\u001b[39;49mweights, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_args)\n\u001b[1;32m    238\u001b[0m splitter \u001b[39m=\u001b[39m ifnone(splitter, meta[\u001b[39m'\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    239\u001b[0m learn \u001b[39m=\u001b[39m Learner(dls\u001b[39m=\u001b[39mdls, model\u001b[39m=\u001b[39mmodel, loss_func\u001b[39m=\u001b[39mloss_func, opt_func\u001b[39m=\u001b[39mopt_func, lr\u001b[39m=\u001b[39mlr, splitter\u001b[39m=\u001b[39msplitter, cbs\u001b[39m=\u001b[39mcbs,\n\u001b[1;32m    240\u001b[0m                metrics\u001b[39m=\u001b[39mmetrics, path\u001b[39m=\u001b[39mpath, model_dir\u001b[39m=\u001b[39mmodel_dir, wd\u001b[39m=\u001b[39mwd, wd_bn_bias\u001b[39m=\u001b[39mwd_bn_bias, train_bn\u001b[39m=\u001b[39mtrain_bn, moms\u001b[39m=\u001b[39mmoms)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:172\u001b[0m, in \u001b[0;36mcreate_vision_model\u001b[0;34m(arch, n_out, pretrained, weights, cut, n_in, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range)\u001b[0m\n\u001b[1;32m    170\u001b[0m     model \u001b[39m=\u001b[39m arch(weights\u001b[39m=\u001b[39mmeta[\u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m (weights \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m pretrained) \u001b[39melse\u001b[39;00m weights)\n\u001b[1;32m    171\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     model \u001b[39m=\u001b[39m arch(pretrained\u001b[39m=\u001b[39;49mpretrained)\n\u001b[1;32m    173\u001b[0m body \u001b[39m=\u001b[39m create_body(model, n_in, pretrained, ifnone(cut, meta[\u001b[39m'\u001b[39m\u001b[39mcut\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m    174\u001b[0m nf \u001b[39m=\u001b[39m num_features_model(nn\u001b[39m.\u001b[39mSequential(\u001b[39m*\u001b[39mbody\u001b[39m.\u001b[39mchildren())) \u001b[39mif\u001b[39;00m custom_head \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: MaskedAutoencoderHiera.forward() got an unexpected keyword argument 'pretrained'"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"facebookresearch/hiera\", model=\"mae_hiera_tiny_224\", pretrained=True, checkpoint=\"mae_in1k\")\n",
    "learn = vision_learner(dls, model, metrics=accuracy, pretrained = True)\n",
    "learn.fine_tune(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat_resnext26ts',\n",
       " 'beit_base_patch16_224',\n",
       " 'beit_base_patch16_384',\n",
       " 'beit_large_patch16_224',\n",
       " 'beit_large_patch16_384',\n",
       " 'beit_large_patch16_512',\n",
       " 'beitv2_base_patch16_224',\n",
       " 'beitv2_large_patch16_224',\n",
       " 'botnet26t_256',\n",
       " 'botnet50ts_256',\n",
       " 'caformer_b36',\n",
       " 'caformer_m36',\n",
       " 'caformer_s18',\n",
       " 'caformer_s36',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_medium',\n",
       " 'coat_lite_medium_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_small',\n",
       " 'coat_tiny',\n",
       " 'coatnet_0_224',\n",
       " 'coatnet_0_rw_224',\n",
       " 'coatnet_1_224',\n",
       " 'coatnet_1_rw_224',\n",
       " 'coatnet_2_224',\n",
       " 'coatnet_2_rw_224',\n",
       " 'coatnet_3_224',\n",
       " 'coatnet_3_rw_224',\n",
       " 'coatnet_4_224',\n",
       " 'coatnet_5_224',\n",
       " 'coatnet_bn_0_rw_224',\n",
       " 'coatnet_nano_cc_224',\n",
       " 'coatnet_nano_rw_224',\n",
       " 'coatnet_pico_rw_224',\n",
       " 'coatnet_rmlp_0_rw_224',\n",
       " 'coatnet_rmlp_1_rw2_224',\n",
       " 'coatnet_rmlp_1_rw_224',\n",
       " 'coatnet_rmlp_2_rw_224',\n",
       " 'coatnet_rmlp_2_rw_384',\n",
       " 'coatnet_rmlp_3_rw_224',\n",
       " 'coatnet_rmlp_nano_rw_224',\n",
       " 'coatnext_nano_rw_224',\n",
       " 'convformer_b36',\n",
       " 'convformer_m36',\n",
       " 'convformer_s18',\n",
       " 'convformer_s36',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'convmixer_768_32',\n",
       " 'convmixer_1024_20_ks9_p14',\n",
       " 'convmixer_1536_20',\n",
       " 'convnext_atto',\n",
       " 'convnext_atto_ols',\n",
       " 'convnext_base',\n",
       " 'convnext_femto',\n",
       " 'convnext_femto_ols',\n",
       " 'convnext_large',\n",
       " 'convnext_large_mlp',\n",
       " 'convnext_nano',\n",
       " 'convnext_nano_ols',\n",
       " 'convnext_pico',\n",
       " 'convnext_pico_ols',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'convnext_tiny_hnf',\n",
       " 'convnext_xlarge',\n",
       " 'convnext_xxlarge',\n",
       " 'convnextv2_atto',\n",
       " 'convnextv2_base',\n",
       " 'convnextv2_femto',\n",
       " 'convnextv2_huge',\n",
       " 'convnextv2_large',\n",
       " 'convnextv2_nano',\n",
       " 'convnextv2_pico',\n",
       " 'convnextv2_small',\n",
       " 'convnextv2_tiny',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'cs3darknet_focus_l',\n",
       " 'cs3darknet_focus_m',\n",
       " 'cs3darknet_focus_s',\n",
       " 'cs3darknet_focus_x',\n",
       " 'cs3darknet_l',\n",
       " 'cs3darknet_m',\n",
       " 'cs3darknet_s',\n",
       " 'cs3darknet_x',\n",
       " 'cs3edgenet_x',\n",
       " 'cs3se_edgenet_x',\n",
       " 'cs3sedarknet_l',\n",
       " 'cs3sedarknet_x',\n",
       " 'cs3sedarknet_xdw',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnet50d',\n",
       " 'cspresnet50w',\n",
       " 'cspresnext50',\n",
       " 'darknet17',\n",
       " 'darknet21',\n",
       " 'darknet53',\n",
       " 'darknetaa53',\n",
       " 'davit_base',\n",
       " 'davit_giant',\n",
       " 'davit_huge',\n",
       " 'davit_large',\n",
       " 'davit_small',\n",
       " 'davit_tiny',\n",
       " 'deit3_base_patch16_224',\n",
       " 'deit3_base_patch16_384',\n",
       " 'deit3_huge_patch14_224',\n",
       " 'deit3_large_patch16_224',\n",
       " 'deit3_large_patch16_384',\n",
       " 'deit3_medium_patch16_224',\n",
       " 'deit3_small_patch16_224',\n",
       " 'deit3_small_patch16_384',\n",
       " 'deit_base_distilled_patch16_224',\n",
       " 'deit_base_distilled_patch16_384',\n",
       " 'deit_base_patch16_224',\n",
       " 'deit_base_patch16_384',\n",
       " 'deit_small_distilled_patch16_224',\n",
       " 'deit_small_patch16_224',\n",
       " 'deit_tiny_distilled_patch16_224',\n",
       " 'deit_tiny_patch16_224',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenet264d',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn48b',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_botnext26ts_256',\n",
       " 'eca_halonext26ts',\n",
       " 'eca_nfnet_l0',\n",
       " 'eca_nfnet_l1',\n",
       " 'eca_nfnet_l2',\n",
       " 'eca_nfnet_l3',\n",
       " 'eca_resnet33ts',\n",
       " 'eca_resnext26ts',\n",
       " 'eca_vovnet39b',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet200d',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'ecaresnext26t_32x4d',\n",
       " 'ecaresnext50t_32x4d',\n",
       " 'edgenext_base',\n",
       " 'edgenext_small',\n",
       " 'edgenext_small_rw',\n",
       " 'edgenext_x_small',\n",
       " 'edgenext_xx_small',\n",
       " 'efficientformer_l1',\n",
       " 'efficientformer_l3',\n",
       " 'efficientformer_l7',\n",
       " 'efficientformerv2_l',\n",
       " 'efficientformerv2_s0',\n",
       " 'efficientformerv2_s1',\n",
       " 'efficientformerv2_s2',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b0_g8_gn',\n",
       " 'efficientnet_b0_g16_evos',\n",
       " 'efficientnet_b0_gn',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_g8_gn',\n",
       " 'efficientnet_b3_gn',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_b8',\n",
       " 'efficientnet_cc_b0_4e',\n",
       " 'efficientnet_cc_b0_8e',\n",
       " 'efficientnet_cc_b1_8e',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_l2',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnet_lite1',\n",
       " 'efficientnet_lite2',\n",
       " 'efficientnet_lite3',\n",
       " 'efficientnet_lite4',\n",
       " 'efficientnetv2_l',\n",
       " 'efficientnetv2_m',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_rw_t',\n",
       " 'efficientnetv2_s',\n",
       " 'efficientnetv2_xl',\n",
       " 'efficientvit_b0',\n",
       " 'efficientvit_b1',\n",
       " 'efficientvit_b2',\n",
       " 'efficientvit_b3',\n",
       " 'efficientvit_l1',\n",
       " 'efficientvit_l2',\n",
       " 'efficientvit_l3',\n",
       " 'efficientvit_m0',\n",
       " 'efficientvit_m1',\n",
       " 'efficientvit_m2',\n",
       " 'efficientvit_m3',\n",
       " 'efficientvit_m4',\n",
       " 'efficientvit_m5',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet19b_slim',\n",
       " 'ese_vovnet19b_slim_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'ese_vovnet39b_evos',\n",
       " 'ese_vovnet57b',\n",
       " 'ese_vovnet99b',\n",
       " 'eva02_base_patch14_224',\n",
       " 'eva02_base_patch14_448',\n",
       " 'eva02_base_patch16_clip_224',\n",
       " 'eva02_enormous_patch14_clip_224',\n",
       " 'eva02_large_patch14_224',\n",
       " 'eva02_large_patch14_448',\n",
       " 'eva02_large_patch14_clip_224',\n",
       " 'eva02_large_patch14_clip_336',\n",
       " 'eva02_small_patch14_224',\n",
       " 'eva02_small_patch14_336',\n",
       " 'eva02_tiny_patch14_224',\n",
       " 'eva02_tiny_patch14_336',\n",
       " 'eva_giant_patch14_224',\n",
       " 'eva_giant_patch14_336',\n",
       " 'eva_giant_patch14_560',\n",
       " 'eva_giant_patch14_clip_224',\n",
       " 'eva_large_patch14_196',\n",
       " 'eva_large_patch14_336',\n",
       " 'fastvit_ma36',\n",
       " 'fastvit_s12',\n",
       " 'fastvit_sa12',\n",
       " 'fastvit_sa24',\n",
       " 'fastvit_sa36',\n",
       " 'fastvit_t8',\n",
       " 'fastvit_t12',\n",
       " 'fbnetc_100',\n",
       " 'fbnetv3_b',\n",
       " 'fbnetv3_d',\n",
       " 'fbnetv3_g',\n",
       " 'flexivit_base',\n",
       " 'flexivit_large',\n",
       " 'flexivit_small',\n",
       " 'focalnet_base_lrf',\n",
       " 'focalnet_base_srf',\n",
       " 'focalnet_huge_fl3',\n",
       " 'focalnet_huge_fl4',\n",
       " 'focalnet_large_fl3',\n",
       " 'focalnet_large_fl4',\n",
       " 'focalnet_small_lrf',\n",
       " 'focalnet_small_srf',\n",
       " 'focalnet_tiny_lrf',\n",
       " 'focalnet_tiny_srf',\n",
       " 'focalnet_xlarge_fl3',\n",
       " 'focalnet_xlarge_fl4',\n",
       " 'gc_efficientnetv2_rw_t',\n",
       " 'gcresnet33ts',\n",
       " 'gcresnet50t',\n",
       " 'gcresnext26ts',\n",
       " 'gcresnext50ts',\n",
       " 'gcvit_base',\n",
       " 'gcvit_small',\n",
       " 'gcvit_tiny',\n",
       " 'gcvit_xtiny',\n",
       " 'gcvit_xxtiny',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'ghostnet_050',\n",
       " 'ghostnet_100',\n",
       " 'ghostnet_130',\n",
       " 'ghostnetv2_100',\n",
       " 'ghostnetv2_130',\n",
       " 'ghostnetv2_160',\n",
       " 'gmixer_12_224',\n",
       " 'gmixer_24_224',\n",
       " 'gmlp_b16_224',\n",
       " 'gmlp_s16_224',\n",
       " 'gmlp_ti16_224',\n",
       " 'halo2botnet50ts_256',\n",
       " 'halonet26t',\n",
       " 'halonet50ts',\n",
       " 'halonet_h1',\n",
       " 'haloregnetz_b',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hgnet_base',\n",
       " 'hgnet_small',\n",
       " 'hgnet_tiny',\n",
       " 'hgnetv2_b0',\n",
       " 'hgnetv2_b1',\n",
       " 'hgnetv2_b2',\n",
       " 'hgnetv2_b3',\n",
       " 'hgnetv2_b4',\n",
       " 'hgnetv2_b5',\n",
       " 'hgnetv2_b6',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w18_ssld',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w48_ssld',\n",
       " 'hrnet_w64',\n",
       " 'inception_next_base',\n",
       " 'inception_next_small',\n",
       " 'inception_next_tiny',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'lambda_resnet26rpt_256',\n",
       " 'lambda_resnet26t',\n",
       " 'lambda_resnet50ts',\n",
       " 'lamhalobotnet50ts_256',\n",
       " 'lcnet_035',\n",
       " 'lcnet_050',\n",
       " 'lcnet_075',\n",
       " 'lcnet_100',\n",
       " 'lcnet_150',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'legacy_xception',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_256d',\n",
       " 'levit_384',\n",
       " 'levit_384_s8',\n",
       " 'levit_512',\n",
       " 'levit_512_s8',\n",
       " 'levit_512d',\n",
       " 'levit_conv_128',\n",
       " 'levit_conv_128s',\n",
       " 'levit_conv_192',\n",
       " 'levit_conv_256',\n",
       " 'levit_conv_256d',\n",
       " 'levit_conv_384',\n",
       " 'levit_conv_384_s8',\n",
       " 'levit_conv_512',\n",
       " 'levit_conv_512_s8',\n",
       " 'levit_conv_512d',\n",
       " 'maxvit_base_tf_224',\n",
       " 'maxvit_base_tf_384',\n",
       " 'maxvit_base_tf_512',\n",
       " 'maxvit_large_tf_224',\n",
       " 'maxvit_large_tf_384',\n",
       " 'maxvit_large_tf_512',\n",
       " 'maxvit_nano_rw_256',\n",
       " 'maxvit_pico_rw_256',\n",
       " 'maxvit_rmlp_base_rw_224',\n",
       " 'maxvit_rmlp_base_rw_384',\n",
       " 'maxvit_rmlp_nano_rw_256',\n",
       " 'maxvit_rmlp_pico_rw_256',\n",
       " 'maxvit_rmlp_small_rw_224',\n",
       " 'maxvit_rmlp_small_rw_256',\n",
       " 'maxvit_rmlp_tiny_rw_256',\n",
       " 'maxvit_small_tf_224',\n",
       " 'maxvit_small_tf_384',\n",
       " 'maxvit_small_tf_512',\n",
       " 'maxvit_tiny_pm_256',\n",
       " 'maxvit_tiny_rw_224',\n",
       " 'maxvit_tiny_rw_256',\n",
       " 'maxvit_tiny_tf_224',\n",
       " 'maxvit_tiny_tf_384',\n",
       " 'maxvit_tiny_tf_512',\n",
       " 'maxvit_xlarge_tf_224',\n",
       " 'maxvit_xlarge_tf_384',\n",
       " 'maxvit_xlarge_tf_512',\n",
       " 'maxxvit_rmlp_nano_rw_256',\n",
       " 'maxxvit_rmlp_small_rw_256',\n",
       " 'maxxvit_rmlp_tiny_rw_256',\n",
       " 'maxxvitv2_nano_rw_256',\n",
       " 'maxxvitv2_rmlp_base_rw_224',\n",
       " 'maxxvitv2_rmlp_base_rw_384',\n",
       " 'maxxvitv2_rmlp_large_rw_224',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b32_224',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l32_224',\n",
       " 'mixer_s16_224',\n",
       " 'mixer_s32_224',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mixnet_xxl',\n",
       " 'mnasnet_050',\n",
       " 'mnasnet_075',\n",
       " 'mnasnet_100',\n",
       " 'mnasnet_140',\n",
       " 'mnasnet_small',\n",
       " 'mobilenetv2_035',\n",
       " 'mobilenetv2_050',\n",
       " 'mobilenetv2_075',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_075',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_rw',\n",
       " 'mobilenetv3_small_050',\n",
       " 'mobilenetv3_small_075',\n",
       " 'mobilenetv3_small_100',\n",
       " 'mobileone_s0',\n",
       " 'mobileone_s1',\n",
       " 'mobileone_s2',\n",
       " 'mobileone_s3',\n",
       " 'mobileone_s4',\n",
       " 'mobilevit_s',\n",
       " 'mobilevit_xs',\n",
       " 'mobilevit_xxs',\n",
       " 'mobilevitv2_050',\n",
       " 'mobilevitv2_075',\n",
       " 'mobilevitv2_100',\n",
       " 'mobilevitv2_125',\n",
       " 'mobilevitv2_150',\n",
       " 'mobilevitv2_175',\n",
       " 'mobilevitv2_200',\n",
       " 'mvitv2_base',\n",
       " 'mvitv2_base_cls',\n",
       " 'mvitv2_huge_cls',\n",
       " 'mvitv2_large',\n",
       " 'mvitv2_large_cls',\n",
       " 'mvitv2_small',\n",
       " 'mvitv2_small_cls',\n",
       " 'mvitv2_tiny',\n",
       " 'nasnetalarge',\n",
       " 'nest_base',\n",
       " 'nest_base_jx',\n",
       " 'nest_small',\n",
       " 'nest_small_jx',\n",
       " 'nest_tiny',\n",
       " 'nest_tiny_jx',\n",
       " 'nextvit_base',\n",
       " 'nextvit_large',\n",
       " 'nextvit_small',\n",
       " 'nf_ecaresnet26',\n",
       " 'nf_ecaresnet50',\n",
       " 'nf_ecaresnet101',\n",
       " 'nf_regnet_b0',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_regnet_b2',\n",
       " 'nf_regnet_b3',\n",
       " 'nf_regnet_b4',\n",
       " 'nf_regnet_b5',\n",
       " 'nf_resnet26',\n",
       " 'nf_resnet50',\n",
       " 'nf_resnet101',\n",
       " 'nf_seresnet26',\n",
       " 'nf_seresnet50',\n",
       " 'nf_seresnet101',\n",
       " 'nfnet_f0',\n",
       " 'nfnet_f1',\n",
       " 'nfnet_f2',\n",
       " 'nfnet_f3',\n",
       " 'nfnet_f4',\n",
       " 'nfnet_f5',\n",
       " 'nfnet_f6',\n",
       " 'nfnet_f7',\n",
       " 'nfnet_l0',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'poolformer_m36',\n",
       " 'poolformer_m48',\n",
       " 'poolformer_s12',\n",
       " 'poolformer_s24',\n",
       " 'poolformer_s36',\n",
       " 'poolformerv2_m36',\n",
       " 'poolformerv2_m48',\n",
       " 'poolformerv2_s12',\n",
       " 'poolformerv2_s24',\n",
       " 'poolformerv2_s36',\n",
       " 'pvt_v2_b0',\n",
       " 'pvt_v2_b1',\n",
       " 'pvt_v2_b2',\n",
       " 'pvt_v2_b2_li',\n",
       " 'pvt_v2_b3',\n",
       " 'pvt_v2_b4',\n",
       " 'pvt_v2_b5',\n",
       " 'regnetv_040',\n",
       " 'regnetv_064',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_004_tv',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_008_tv',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_040_sgn',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_080_tv',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'regnety_640',\n",
       " 'regnety_1280',\n",
       " 'regnety_2560',\n",
       " 'regnetz_005',\n",
       " 'regnetz_040',\n",
       " 'regnetz_040_h',\n",
       " 'regnetz_b16',\n",
       " 'regnetz_b16_evos',\n",
       " 'regnetz_c16',\n",
       " 'regnetz_c16_evos',\n",
       " 'regnetz_d8',\n",
       " 'regnetz_d8_evos',\n",
       " 'regnetz_d32',\n",
       " 'regnetz_e8',\n",
       " 'repghostnet_050',\n",
       " 'repghostnet_058',\n",
       " 'repghostnet_080',\n",
       " 'repghostnet_100',\n",
       " 'repghostnet_111',\n",
       " 'repghostnet_130',\n",
       " 'repghostnet_150',\n",
       " 'repghostnet_200',\n",
       " 'repvgg_a0',\n",
       " 'repvgg_a1',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'repvgg_d2se',\n",
       " 'repvit_m0_9',\n",
       " 'repvit_m1',\n",
       " 'repvit_m1_0',\n",
       " 'repvit_m1_1',\n",
       " 'repvit_m1_5',\n",
       " 'repvit_m2',\n",
       " 'repvit_m2_3',\n",
       " 'repvit_m3',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net50d',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2net101d',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224',\n",
       " 'resmlp_24_224',\n",
       " 'resmlp_36_224',\n",
       " 'resmlp_big_24_224',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet10t',\n",
       " 'resnet14t',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet32ts',\n",
       " 'resnet33ts',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_gn',\n",
       " 'resnet50c',\n",
       " 'resnet50d',\n",
       " 'resnet50s',\n",
       " 'resnet50t',\n",
       " 'resnet51q',\n",
       " 'resnet61q',\n",
       " 'resnet101',\n",
       " 'resnet101c',\n",
       " 'resnet101d',\n",
       " 'resnet101s',\n",
       " 'resnet152',\n",
       " 'resnet152c',\n",
       " 'resnet152d',\n",
       " 'resnet152s',\n",
       " 'resnet200',\n",
       " 'resnet200d',\n",
       " 'resnetaa34d',\n",
       " 'resnetaa50',\n",
       " 'resnetaa50d',\n",
       " 'resnetaa101d',\n",
       " 'resnetblur18',\n",
       " 'resnetblur50',\n",
       " 'resnetblur50d',\n",
       " 'resnetblur101d',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50',\n",
       " 'resnetv2_50d',\n",
       " 'resnetv2_50d_evos',\n",
       " 'resnetv2_50d_frn',\n",
       " 'resnetv2_50d_gn',\n",
       " 'resnetv2_50t',\n",
       " 'resnetv2_50x1_bit',\n",
       " 'resnetv2_50x3_bit',\n",
       " 'resnetv2_101',\n",
       " 'resnetv2_101d',\n",
       " 'resnetv2_101x1_bit',\n",
       " 'resnetv2_101x3_bit',\n",
       " 'resnetv2_152',\n",
       " 'resnetv2_152d',\n",
       " 'resnetv2_152x2_bit',\n",
       " 'resnetv2_152x4_bit',\n",
       " 'resnext26ts',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_32x16d',\n",
       " 'resnext101_32x32d',\n",
       " 'resnext101_64x4d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'rexnet_300',\n",
       " 'rexnetr_100',\n",
       " 'rexnetr_130',\n",
       " 'rexnetr_150',\n",
       " 'rexnetr_200',\n",
       " 'rexnetr_300',\n",
       " 'samvit_base_patch16',\n",
       " 'samvit_base_patch16_224',\n",
       " 'samvit_huge_patch16',\n",
       " 'samvit_large_patch16',\n",
       " 'sebotnet33ts_256',\n",
       " 'sedarknet21',\n",
       " 'sehalonet33ts',\n",
       " 'selecsls42',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'selecsls84',\n",
       " 'semnasnet_050',\n",
       " 'semnasnet_075',\n",
       " 'semnasnet_100',\n",
       " 'semnasnet_140',\n",
       " 'senet154',\n",
       " 'sequencer2d_l',\n",
       " 'sequencer2d_m',\n",
       " 'sequencer2d_s',\n",
       " 'seresnet18',\n",
       " 'seresnet33ts',\n",
       " 'seresnet34',\n",
       " 'seresnet50',\n",
       " 'seresnet50t',\n",
       " 'seresnet101',\n",
       " 'seresnet152',\n",
       " 'seresnet152d',\n",
       " 'seresnet200d',\n",
       " 'seresnet269d',\n",
       " 'seresnetaa50d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26ts',\n",
       " 'seresnext50_32x4d',\n",
       " 'seresnext101_32x4d',\n",
       " 'seresnext101_32x8d',\n",
       " 'seresnext101_64x4d',\n",
       " 'seresnext101d_32x8d',\n",
       " 'seresnextaa101d_32x8d',\n",
       " 'seresnextaa201d_32x8d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnet50',\n",
       " 'skresnet50d',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_s3_base_224',\n",
       " 'swin_s3_small_224',\n",
       " 'swin_s3_tiny_224',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swinv2_base_window8_256',\n",
       " 'swinv2_base_window12_192',\n",
       " 'swinv2_base_window12to16_192to256',\n",
       " 'swinv2_base_window12to24_192to384',\n",
       " 'swinv2_base_window16_256',\n",
       " 'swinv2_cr_base_224',\n",
       " 'swinv2_cr_base_384',\n",
       " 'swinv2_cr_base_ns_224',\n",
       " 'swinv2_cr_giant_224',\n",
       " 'swinv2_cr_giant_384',\n",
       " 'swinv2_cr_huge_224',\n",
       " 'swinv2_cr_huge_384',\n",
       " 'swinv2_cr_large_224',\n",
       " 'swinv2_cr_large_384',\n",
       " 'swinv2_cr_small_224',\n",
       " 'swinv2_cr_small_384',\n",
       " 'swinv2_cr_small_ns_224',\n",
       " 'swinv2_cr_small_ns_256',\n",
       " 'swinv2_cr_tiny_224',\n",
       " 'swinv2_cr_tiny_384',\n",
       " 'swinv2_cr_tiny_ns_224',\n",
       " 'swinv2_large_window12_192',\n",
       " 'swinv2_large_window12to16_192to256',\n",
       " 'swinv2_large_window12to24_192to384',\n",
       " 'swinv2_small_window8_256',\n",
       " 'swinv2_small_window16_256',\n",
       " 'swinv2_tiny_window8_256',\n",
       " 'swinv2_tiny_window16_256',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_xl',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tiny_vit_5m_224',\n",
       " 'tiny_vit_11m_224',\n",
       " 'tiny_vit_21m_224',\n",
       " 'tiny_vit_21m_384',\n",
       " 'tiny_vit_21m_512',\n",
       " 'tinynet_a',\n",
       " 'tinynet_b',\n",
       " 'tinynet_c',\n",
       " 'tinynet_d',\n",
       " 'tinynet_e',\n",
       " 'tnt_b_patch16_224',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_m',\n",
       " 'tresnet_v2_l',\n",
       " 'tresnet_xl',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'visformer_tiny',\n",
       " 'vit_base_patch8_224',\n",
       " 'vit_base_patch14_dinov2',\n",
       " 'vit_base_patch14_reg4_dinov2',\n",
       " 'vit_base_patch16_18x2_224',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_clip_224',\n",
       " 'vit_base_patch16_clip_384',\n",
       " 'vit_base_patch16_clip_quickgelu_224',\n",
       " 'vit_base_patch16_gap_224',\n",
       " 'vit_base_patch16_plus_240',\n",
       " 'vit_base_patch16_reg4_gap_256',\n",
       " 'vit_base_patch16_rpn_224',\n",
       " 'vit_base_patch16_siglip_224',\n",
       " 'vit_base_patch16_siglip_256',\n",
       " 'vit_base_patch16_siglip_384',\n",
       " 'vit_base_patch16_siglip_512',\n",
       " 'vit_base_patch16_xp_224',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_patch32_clip_224',\n",
       " 'vit_base_patch32_clip_256',\n",
       " 'vit_base_patch32_clip_384',\n",
       " 'vit_base_patch32_clip_448',\n",
       " 'vit_base_patch32_clip_quickgelu_224',\n",
       " 'vit_base_patch32_plus_256',\n",
       " 'vit_base_r26_s32_224',\n",
       " 'vit_base_r50_s16_224',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_base_resnet26d_224',\n",
       " 'vit_base_resnet50d_224',\n",
       " 'vit_giant_patch14_224',\n",
       " 'vit_giant_patch14_clip_224',\n",
       " 'vit_giant_patch14_dinov2',\n",
       " 'vit_giant_patch14_reg4_dinov2',\n",
       " 'vit_giant_patch16_gap_224',\n",
       " 'vit_gigantic_patch14_224',\n",
       " 'vit_gigantic_patch14_clip_224',\n",
       " 'vit_huge_patch14_224',\n",
       " 'vit_huge_patch14_clip_224',\n",
       " 'vit_huge_patch14_clip_336',\n",
       " 'vit_huge_patch14_clip_378',\n",
       " 'vit_huge_patch14_clip_quickgelu_224',\n",
       " 'vit_huge_patch14_clip_quickgelu_378',\n",
       " 'vit_huge_patch14_gap_224',\n",
       " 'vit_huge_patch14_xp_224',\n",
       " 'vit_huge_patch16_gap_448',\n",
       " 'vit_large_patch14_224',\n",
       " 'vit_large_patch14_clip_224',\n",
       " 'vit_large_patch14_clip_336',\n",
       " 'vit_large_patch14_clip_quickgelu_224',\n",
       " 'vit_large_patch14_clip_quickgelu_336',\n",
       " 'vit_large_patch14_dinov2',\n",
       " 'vit_large_patch14_reg4_dinov2',\n",
       " 'vit_large_patch14_xp_224',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch16_siglip_256',\n",
       " 'vit_large_patch16_siglip_384',\n",
       " 'vit_large_patch32_224',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_medium_patch16_gap_240',\n",
       " 'vit_medium_patch16_gap_256',\n",
       " 'vit_medium_patch16_gap_384',\n",
       " 'vit_medium_patch16_reg4_256',\n",
       " 'vit_medium_patch16_reg4_gap_256',\n",
       " 'vit_relpos_base_patch16_224',\n",
       " 'vit_relpos_base_patch16_cls_224',\n",
       " 'vit_relpos_base_patch16_clsgap_224',\n",
       " 'vit_relpos_base_patch16_plus_240',\n",
       " 'vit_relpos_base_patch16_rpn_224',\n",
       " 'vit_relpos_base_patch32_plus_rpn_256',\n",
       " 'vit_relpos_medium_patch16_224',\n",
       " 'vit_relpos_medium_patch16_cls_224',\n",
       " 'vit_relpos_medium_patch16_rpn_224',\n",
       " 'vit_relpos_small_patch16_224',\n",
       " 'vit_relpos_small_patch16_rpn_224',\n",
       " 'vit_small_patch8_224',\n",
       " 'vit_small_patch14_dinov2',\n",
       " 'vit_small_patch14_reg4_dinov2',\n",
       " 'vit_small_patch16_18x2_224',\n",
       " 'vit_small_patch16_36x1_224',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_small_resnet26d_224',\n",
       " 'vit_small_resnet50d_s16_224',\n",
       " 'vit_so150m_patch16_reg4_gap_256',\n",
       " 'vit_so150m_patch16_reg4_map_256',\n",
       " 'vit_so400m_patch14_siglip_224',\n",
       " 'vit_so400m_patch14_siglip_384',\n",
       " 'vit_srelpos_medium_patch16_224',\n",
       " 'vit_srelpos_small_patch16_224',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_384',\n",
       " 'volo_d1_224',\n",
       " 'volo_d1_384',\n",
       " 'volo_d2_224',\n",
       " 'volo_d2_384',\n",
       " 'volo_d3_224',\n",
       " 'volo_d3_448',\n",
       " 'volo_d4_224',\n",
       " 'volo_d4_448',\n",
       " 'volo_d5_224',\n",
       " 'volo_d5_448',\n",
       " 'volo_d5_512',\n",
       " 'vovnet39a',\n",
       " 'vovnet57a',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception41',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm \n",
    "models = timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(model) for model in models if \"hiera\" in model.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(model) for model in models if \"facebookresearch\" in model.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Restarted .venv (Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/folds/fold_0.csv\")\n",
    "df = df.rename({\"class_id\":\"label\"}, axis = 1)\n",
    "\n",
    "datablock = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),  # Define the type of input and output blocks\n",
    "    get_x=ColReader('image_path'),       # Function to get the image files\n",
    "    get_y=ColReader('label'),            # Function to get the labels\n",
    "    splitter=RandomSplitter(valid_pct=0.2),  # Split data into training and validation sets\n",
    "    item_tfms=Resize(224)                # Resize images to 224x224 pixels\n",
    ")\n",
    "\n",
    "dls = datablock.dataloaders(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/zeus/.cache/torch/hub/facebookresearch_hiera_main\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MaskedAutoencoderHiera.forward() got an unexpected keyword argument 'pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m/teamspace/studios/this_studio/scripts/get_dataloader.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhub\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mfacebookresearch/hiera\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmae_hiera_tiny_224\u001b[39m\u001b[39m\"\u001b[39m, pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, checkpoint\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmae_in1k\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m learn \u001b[39m=\u001b[39m vision_learner(dls, model, metrics\u001b[39m=\u001b[39;49maccuracy, pretrained \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      4\u001b[0m learn\u001b[39m.\u001b[39mfine_tune(\u001b[39m6\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:236\u001b[0m, in \u001b[0;36mvision_learner\u001b[0;34m(dls, arch, normalize, n_out, pretrained, weights, loss_func, opt_func, lr, splitter, cbs, metrics, path, model_dir, wd, wd_bn_bias, train_bn, moms, cut, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[39mif\u001b[39;00m normalize: _add_norm(dls, meta, pretrained, n_in)\n\u001b[0;32m--> 236\u001b[0m     model \u001b[39m=\u001b[39m create_vision_model(arch, n_out, pretrained\u001b[39m=\u001b[39;49mpretrained, weights\u001b[39m=\u001b[39;49mweights, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_args)\n\u001b[1;32m    238\u001b[0m splitter \u001b[39m=\u001b[39m ifnone(splitter, meta[\u001b[39m'\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    239\u001b[0m learn \u001b[39m=\u001b[39m Learner(dls\u001b[39m=\u001b[39mdls, model\u001b[39m=\u001b[39mmodel, loss_func\u001b[39m=\u001b[39mloss_func, opt_func\u001b[39m=\u001b[39mopt_func, lr\u001b[39m=\u001b[39mlr, splitter\u001b[39m=\u001b[39msplitter, cbs\u001b[39m=\u001b[39mcbs,\n\u001b[1;32m    240\u001b[0m                metrics\u001b[39m=\u001b[39mmetrics, path\u001b[39m=\u001b[39mpath, model_dir\u001b[39m=\u001b[39mmodel_dir, wd\u001b[39m=\u001b[39mwd, wd_bn_bias\u001b[39m=\u001b[39mwd_bn_bias, train_bn\u001b[39m=\u001b[39mtrain_bn, moms\u001b[39m=\u001b[39mmoms)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:172\u001b[0m, in \u001b[0;36mcreate_vision_model\u001b[0;34m(arch, n_out, pretrained, weights, cut, n_in, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range)\u001b[0m\n\u001b[1;32m    170\u001b[0m     model \u001b[39m=\u001b[39m arch(weights\u001b[39m=\u001b[39mmeta[\u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m (weights \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m pretrained) \u001b[39melse\u001b[39;00m weights)\n\u001b[1;32m    171\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     model \u001b[39m=\u001b[39m arch(pretrained\u001b[39m=\u001b[39;49mpretrained)\n\u001b[1;32m    173\u001b[0m body \u001b[39m=\u001b[39m create_body(model, n_in, pretrained, ifnone(cut, meta[\u001b[39m'\u001b[39m\u001b[39mcut\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m    174\u001b[0m nf \u001b[39m=\u001b[39m num_features_model(nn\u001b[39m.\u001b[39mSequential(\u001b[39m*\u001b[39mbody\u001b[39m.\u001b[39mchildren())) \u001b[39mif\u001b[39;00m custom_head \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: MaskedAutoencoderHiera.forward() got an unexpected keyword argument 'pretrained'"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"facebookresearch/hiera\", model=\"mae_hiera_tiny_224\", pretrained=True, checkpoint=\"mae_in1k\")\n",
    "learn = vision_learner(dls, model, metrics=accuracy, pretrained = True)\n",
    "learn.fine_tune(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "import timm \n",
    "models = timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "[print(model) for model in models if \"hiera\" in model.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm \n",
    "models = timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiera_base_224\n",
      "hiera_base_plus_224\n",
      "hiera_huge_224\n",
      "hiera_large_224\n",
      "hiera_small_224\n",
      "hiera_tiny_224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(model) for model in models if \"hiera\" in model.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/.venv/lib/python3.10/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/hiera/hiera_tiny_224.pth\" to /home/zeus/.cache/torch/hub/checkpoints/hiera_tiny_224.pth\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Hiera:\n\tsize mismatch for head.projection.weight: copying a param with shape torch.Size([1000, 768]) from checkpoint, the shape in current model is torch.Size([0, 768]).\n\tsize mismatch for head.projection.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([0]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m/teamspace/studios/this_studio/scripts/get_dataloader.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m learn \u001b[39m=\u001b[39m vision_learner(dls, \u001b[39m\"\u001b[39;49m\u001b[39mhiera_tiny_224\u001b[39;49m\u001b[39m\"\u001b[39;49m, metrics\u001b[39m=\u001b[39;49maccuracy)\n\u001b[1;32m      3\u001b[0m learn\u001b[39m.\u001b[39mfine_tune(\u001b[39m6\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:232\u001b[0m, in \u001b[0;36mvision_learner\u001b[0;34m(dls, arch, normalize, n_out, pretrained, weights, loss_func, opt_func, lr, splitter, cbs, metrics, path, model_dir, wd, wd_bn_bias, train_bn, moms, cut, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m n_in \u001b[39m=\u001b[39m kwargs[\u001b[39m'\u001b[39m\u001b[39mn_in\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mn_in\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m \u001b[39m3\u001b[39m\n\u001b[1;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arch, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 232\u001b[0m     model,cfg \u001b[39m=\u001b[39m create_timm_model(arch, n_out, default_split, pretrained, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_args)\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m normalize: _timm_norm(dls, cfg, pretrained, n_in)\n\u001b[1;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:191\u001b[0m, in \u001b[0;36mcreate_timm_model\u001b[0;34m(arch, n_out, cut, pretrained, n_in, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_timm_model\u001b[39m(arch, n_out, cut\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, n_in\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, init\u001b[39m=\u001b[39mnn\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39mkaiming_normal_, custom_head\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    189\u001b[0m                      concat_pool\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, pool\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, lin_ftrs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ps\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, first_bn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, bn_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, lin_first\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, y_range\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    190\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCreate custom architecture using `arch`, `n_in` and `n_out` from the `timm` library\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 191\u001b[0m     model \u001b[39m=\u001b[39m timm\u001b[39m.\u001b[39;49mcreate_model(arch, pretrained\u001b[39m=\u001b[39;49mpretrained, num_classes\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, in_chans\u001b[39m=\u001b[39;49mn_in, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    192\u001b[0m     body \u001b[39m=\u001b[39m TimmBody(model, pretrained, \u001b[39mNone\u001b[39;00m, n_in)\n\u001b[1;32m    193\u001b[0m     nf \u001b[39m=\u001b[39m body\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnum_features\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/_factory.py:117\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m create_fn \u001b[39m=\u001b[39m model_entrypoint(model_name)\n\u001b[1;32m    116\u001b[0m \u001b[39mwith\u001b[39;00m set_layer_config(scriptable\u001b[39m=\u001b[39mscriptable, exportable\u001b[39m=\u001b[39mexportable, no_jit\u001b[39m=\u001b[39mno_jit):\n\u001b[0;32m--> 117\u001b[0m     model \u001b[39m=\u001b[39m create_fn(\n\u001b[1;32m    118\u001b[0m         pretrained\u001b[39m=\u001b[39;49mpretrained,\n\u001b[1;32m    119\u001b[0m         pretrained_cfg\u001b[39m=\u001b[39;49mpretrained_cfg,\n\u001b[1;32m    120\u001b[0m         pretrained_cfg_overlay\u001b[39m=\u001b[39;49mpretrained_cfg_overlay,\n\u001b[1;32m    121\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    122\u001b[0m     )\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m checkpoint_path:\n\u001b[1;32m    125\u001b[0m     load_checkpoint(model, checkpoint_path)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/hiera.py:843\u001b[0m, in \u001b[0;36mhiera_tiny_224\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[39m@register_model\u001b[39m\n\u001b[1;32m    841\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhiera_tiny_224\u001b[39m(pretrained \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    842\u001b[0m     model_args \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(embed_dim\u001b[39m=\u001b[39m\u001b[39m96\u001b[39m, num_heads\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, stages\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m2\u001b[39m))\n\u001b[0;32m--> 843\u001b[0m     \u001b[39mreturn\u001b[39;00m _create_hiera(\u001b[39m'\u001b[39;49m\u001b[39mhiera_tiny_224\u001b[39;49m\u001b[39m'\u001b[39;49m, pretrained\u001b[39m=\u001b[39;49mpretrained, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(model_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/hiera.py:830\u001b[0m, in \u001b[0;36m_create_hiera\u001b[0;34m(variant, pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_hiera\u001b[39m(variant: \u001b[39mstr\u001b[39m, pretrained: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Hiera:\n\u001b[1;32m    828\u001b[0m     out_indices \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mout_indices\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m4\u001b[39m)\n\u001b[0;32m--> 830\u001b[0m     \u001b[39mreturn\u001b[39;00m build_model_with_cfg(\n\u001b[1;32m    831\u001b[0m         Hiera,\n\u001b[1;32m    832\u001b[0m         variant,\n\u001b[1;32m    833\u001b[0m         pretrained,\n\u001b[1;32m    834\u001b[0m         \u001b[39m#pretrained_strict=False,\u001b[39;49;00m\n\u001b[1;32m    835\u001b[0m         pretrained_filter_fn\u001b[39m=\u001b[39;49mcheckpoint_filter_fn,\n\u001b[1;32m    836\u001b[0m         feature_cfg\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(out_indices\u001b[39m=\u001b[39;49mout_indices, feature_cls\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgetter\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m    837\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    838\u001b[0m     )\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/_builder.py:410\u001b[0m, in \u001b[0;36mbuild_model_with_cfg\u001b[0;34m(model_cls, variant, pretrained, pretrained_cfg, pretrained_cfg_overlay, model_cfg, feature_cfg, pretrained_strict, pretrained_filter_fn, kwargs_filter, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m num_classes_pretrained \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m features \u001b[39melse\u001b[39;00m \u001b[39mgetattr\u001b[39m(model, \u001b[39m'\u001b[39m\u001b[39mnum_classes\u001b[39m\u001b[39m'\u001b[39m, kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mnum_classes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1000\u001b[39m))\n\u001b[1;32m    409\u001b[0m \u001b[39mif\u001b[39;00m pretrained:\n\u001b[0;32m--> 410\u001b[0m     load_pretrained(\n\u001b[1;32m    411\u001b[0m         model,\n\u001b[1;32m    412\u001b[0m         pretrained_cfg\u001b[39m=\u001b[39;49mpretrained_cfg,\n\u001b[1;32m    413\u001b[0m         num_classes\u001b[39m=\u001b[39;49mnum_classes_pretrained,\n\u001b[1;32m    414\u001b[0m         in_chans\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39min_chans\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m3\u001b[39;49m),\n\u001b[1;32m    415\u001b[0m         filter_fn\u001b[39m=\u001b[39;49mpretrained_filter_fn,\n\u001b[1;32m    416\u001b[0m         strict\u001b[39m=\u001b[39;49mpretrained_strict,\n\u001b[1;32m    417\u001b[0m     )\n\u001b[1;32m    419\u001b[0m \u001b[39m# Wrap the model in a feature extraction module if enabled\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m features:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/_builder.py:237\u001b[0m, in \u001b[0;36mload_pretrained\u001b[0;34m(model, pretrained_cfg, num_classes, in_chans, filter_fn, strict)\u001b[0m\n\u001b[1;32m    234\u001b[0m             classifier_bias \u001b[39m=\u001b[39m state_dict[classifier_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.bias\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    235\u001b[0m             state_dict[classifier_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.bias\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m classifier_bias[label_offset:]\n\u001b[0;32m--> 237\u001b[0m load_result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mload_state_dict(state_dict, strict\u001b[39m=\u001b[39;49mstrict)\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m load_result\u001b[39m.\u001b[39mmissing_keys:\n\u001b[1;32m    239\u001b[0m     _logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    240\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMissing keys (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(load_result\u001b[39m.\u001b[39mmissing_keys)\u001b[39m}\u001b[39;00m\u001b[39m) discovered while loading pretrained weights.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    241\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m This is expected if model is being adapted.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Hiera:\n\tsize mismatch for head.projection.weight: copying a param with shape torch.Size([1000, 768]) from checkpoint, the shape in current model is torch.Size([0, 768]).\n\tsize mismatch for head.projection.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([0])."
     ]
    }
   ],
   "source": [
    "learn = vision_learner(dls, \"hiera_tiny_224\", metrics=accuracy)\n",
    "learn.fine_tune(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hiera_tiny_224']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm \n",
    "timm.list_models(\"hiera_tiny_224\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Restarted .venv (Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/folds/fold_0.csv\")\n",
    "df = df.rename({\"class_id\":\"label\"}, axis = 1)\n",
    "\n",
    "datablock = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),  # Define the type of input and output blocks\n",
    "    get_x=ColReader('image_path'),       # Function to get the image files\n",
    "    get_y=ColReader('label'),            # Function to get the labels\n",
    "    splitter=RandomSplitter(valid_pct=0.2),  # Split data into training and validation sets\n",
    "    item_tfms=Resize(224)                # Resize images to 224x224 pixels\n",
    ")\n",
    "\n",
    "dls = datablock.dataloaders(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/.venv/lib/python3.10/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Hiera:\n\tsize mismatch for head.projection.weight: copying a param with shape torch.Size([1000, 768]) from checkpoint, the shape in current model is torch.Size([0, 768]).\n\tsize mismatch for head.projection.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([0]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m/teamspace/studios/this_studio/scripts/get_dataloader.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m learn \u001b[39m=\u001b[39m vision_learner(dls, \u001b[39m\"\u001b[39;49m\u001b[39mhiera_tiny_224\u001b[39;49m\u001b[39m\"\u001b[39;49m, metrics\u001b[39m=\u001b[39;49maccuracy)\n\u001b[1;32m      3\u001b[0m learn\u001b[39m.\u001b[39mfine_tune(\u001b[39m6\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:232\u001b[0m, in \u001b[0;36mvision_learner\u001b[0;34m(dls, arch, normalize, n_out, pretrained, weights, loss_func, opt_func, lr, splitter, cbs, metrics, path, model_dir, wd, wd_bn_bias, train_bn, moms, cut, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m n_in \u001b[39m=\u001b[39m kwargs[\u001b[39m'\u001b[39m\u001b[39mn_in\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mn_in\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m \u001b[39m3\u001b[39m\n\u001b[1;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arch, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 232\u001b[0m     model,cfg \u001b[39m=\u001b[39m create_timm_model(arch, n_out, default_split, pretrained, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_args)\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m normalize: _timm_norm(dls, cfg, pretrained, n_in)\n\u001b[1;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:191\u001b[0m, in \u001b[0;36mcreate_timm_model\u001b[0;34m(arch, n_out, cut, pretrained, n_in, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_timm_model\u001b[39m(arch, n_out, cut\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, n_in\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, init\u001b[39m=\u001b[39mnn\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39mkaiming_normal_, custom_head\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    189\u001b[0m                      concat_pool\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, pool\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, lin_ftrs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ps\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, first_bn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, bn_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, lin_first\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, y_range\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    190\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCreate custom architecture using `arch`, `n_in` and `n_out` from the `timm` library\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 191\u001b[0m     model \u001b[39m=\u001b[39m timm\u001b[39m.\u001b[39;49mcreate_model(arch, pretrained\u001b[39m=\u001b[39;49mpretrained, num_classes\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, in_chans\u001b[39m=\u001b[39;49mn_in, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    192\u001b[0m     body \u001b[39m=\u001b[39m TimmBody(model, pretrained, \u001b[39mNone\u001b[39;00m, n_in)\n\u001b[1;32m    193\u001b[0m     nf \u001b[39m=\u001b[39m body\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnum_features\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/_factory.py:117\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m create_fn \u001b[39m=\u001b[39m model_entrypoint(model_name)\n\u001b[1;32m    116\u001b[0m \u001b[39mwith\u001b[39;00m set_layer_config(scriptable\u001b[39m=\u001b[39mscriptable, exportable\u001b[39m=\u001b[39mexportable, no_jit\u001b[39m=\u001b[39mno_jit):\n\u001b[0;32m--> 117\u001b[0m     model \u001b[39m=\u001b[39m create_fn(\n\u001b[1;32m    118\u001b[0m         pretrained\u001b[39m=\u001b[39;49mpretrained,\n\u001b[1;32m    119\u001b[0m         pretrained_cfg\u001b[39m=\u001b[39;49mpretrained_cfg,\n\u001b[1;32m    120\u001b[0m         pretrained_cfg_overlay\u001b[39m=\u001b[39;49mpretrained_cfg_overlay,\n\u001b[1;32m    121\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    122\u001b[0m     )\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m checkpoint_path:\n\u001b[1;32m    125\u001b[0m     load_checkpoint(model, checkpoint_path)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/hiera.py:843\u001b[0m, in \u001b[0;36mhiera_tiny_224\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[39m@register_model\u001b[39m\n\u001b[1;32m    841\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhiera_tiny_224\u001b[39m(pretrained \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    842\u001b[0m     model_args \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(embed_dim\u001b[39m=\u001b[39m\u001b[39m96\u001b[39m, num_heads\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, stages\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m2\u001b[39m))\n\u001b[0;32m--> 843\u001b[0m     \u001b[39mreturn\u001b[39;00m _create_hiera(\u001b[39m'\u001b[39;49m\u001b[39mhiera_tiny_224\u001b[39;49m\u001b[39m'\u001b[39;49m, pretrained\u001b[39m=\u001b[39;49mpretrained, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(model_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/hiera.py:830\u001b[0m, in \u001b[0;36m_create_hiera\u001b[0;34m(variant, pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_hiera\u001b[39m(variant: \u001b[39mstr\u001b[39m, pretrained: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Hiera:\n\u001b[1;32m    828\u001b[0m     out_indices \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mout_indices\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m4\u001b[39m)\n\u001b[0;32m--> 830\u001b[0m     \u001b[39mreturn\u001b[39;00m build_model_with_cfg(\n\u001b[1;32m    831\u001b[0m         Hiera,\n\u001b[1;32m    832\u001b[0m         variant,\n\u001b[1;32m    833\u001b[0m         pretrained,\n\u001b[1;32m    834\u001b[0m         \u001b[39m#pretrained_strict=False,\u001b[39;49;00m\n\u001b[1;32m    835\u001b[0m         pretrained_filter_fn\u001b[39m=\u001b[39;49mcheckpoint_filter_fn,\n\u001b[1;32m    836\u001b[0m         feature_cfg\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(out_indices\u001b[39m=\u001b[39;49mout_indices, feature_cls\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgetter\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m    837\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    838\u001b[0m     )\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/_builder.py:410\u001b[0m, in \u001b[0;36mbuild_model_with_cfg\u001b[0;34m(model_cls, variant, pretrained, pretrained_cfg, pretrained_cfg_overlay, model_cfg, feature_cfg, pretrained_strict, pretrained_filter_fn, kwargs_filter, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m num_classes_pretrained \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m features \u001b[39melse\u001b[39;00m \u001b[39mgetattr\u001b[39m(model, \u001b[39m'\u001b[39m\u001b[39mnum_classes\u001b[39m\u001b[39m'\u001b[39m, kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mnum_classes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1000\u001b[39m))\n\u001b[1;32m    409\u001b[0m \u001b[39mif\u001b[39;00m pretrained:\n\u001b[0;32m--> 410\u001b[0m     load_pretrained(\n\u001b[1;32m    411\u001b[0m         model,\n\u001b[1;32m    412\u001b[0m         pretrained_cfg\u001b[39m=\u001b[39;49mpretrained_cfg,\n\u001b[1;32m    413\u001b[0m         num_classes\u001b[39m=\u001b[39;49mnum_classes_pretrained,\n\u001b[1;32m    414\u001b[0m         in_chans\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39min_chans\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m3\u001b[39;49m),\n\u001b[1;32m    415\u001b[0m         filter_fn\u001b[39m=\u001b[39;49mpretrained_filter_fn,\n\u001b[1;32m    416\u001b[0m         strict\u001b[39m=\u001b[39;49mpretrained_strict,\n\u001b[1;32m    417\u001b[0m     )\n\u001b[1;32m    419\u001b[0m \u001b[39m# Wrap the model in a feature extraction module if enabled\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m features:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/_builder.py:237\u001b[0m, in \u001b[0;36mload_pretrained\u001b[0;34m(model, pretrained_cfg, num_classes, in_chans, filter_fn, strict)\u001b[0m\n\u001b[1;32m    234\u001b[0m             classifier_bias \u001b[39m=\u001b[39m state_dict[classifier_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.bias\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    235\u001b[0m             state_dict[classifier_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.bias\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m classifier_bias[label_offset:]\n\u001b[0;32m--> 237\u001b[0m load_result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mload_state_dict(state_dict, strict\u001b[39m=\u001b[39;49mstrict)\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m load_result\u001b[39m.\u001b[39mmissing_keys:\n\u001b[1;32m    239\u001b[0m     _logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    240\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMissing keys (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(load_result\u001b[39m.\u001b[39mmissing_keys)\u001b[39m}\u001b[39;00m\u001b[39m) discovered while loading pretrained weights.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    241\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m This is expected if model is being adapted.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Hiera:\n\tsize mismatch for head.projection.weight: copying a param with shape torch.Size([1000, 768]) from checkpoint, the shape in current model is torch.Size([0, 768]).\n\tsize mismatch for head.projection.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([0])."
     ]
    }
   ],
   "source": [
    "learn = vision_learner(dls, \"hiera_tiny_224\", metrics=accuracy)\n",
    "learn.fine_tune(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(\"hiera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/.venv/lib/python3.10/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/hiera/hiera_small_224.pth\" to /home/zeus/.cache/torch/hub/checkpoints/hiera_small_224.pth\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Hiera:\n\tsize mismatch for head.projection.weight: copying a param with shape torch.Size([1000, 768]) from checkpoint, the shape in current model is torch.Size([0, 768]).\n\tsize mismatch for head.projection.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([0]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m/teamspace/studios/this_studio/scripts/get_dataloader.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m learn \u001b[39m=\u001b[39m vision_learner(dls, \u001b[39m\"\u001b[39;49m\u001b[39mhiera_small_224\u001b[39;49m\u001b[39m\"\u001b[39;49m, metrics\u001b[39m=\u001b[39;49maccuracy)\n\u001b[1;32m      3\u001b[0m learn\u001b[39m.\u001b[39mfine_tune(\u001b[39m6\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:232\u001b[0m, in \u001b[0;36mvision_learner\u001b[0;34m(dls, arch, normalize, n_out, pretrained, weights, loss_func, opt_func, lr, splitter, cbs, metrics, path, model_dir, wd, wd_bn_bias, train_bn, moms, cut, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m n_in \u001b[39m=\u001b[39m kwargs[\u001b[39m'\u001b[39m\u001b[39mn_in\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mn_in\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m \u001b[39m3\u001b[39m\n\u001b[1;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arch, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 232\u001b[0m     model,cfg \u001b[39m=\u001b[39m create_timm_model(arch, n_out, default_split, pretrained, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_args)\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m normalize: _timm_norm(dls, cfg, pretrained, n_in)\n\u001b[1;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/fastai/vision/learner.py:191\u001b[0m, in \u001b[0;36mcreate_timm_model\u001b[0;34m(arch, n_out, cut, pretrained, n_in, init, custom_head, concat_pool, pool, lin_ftrs, ps, first_bn, bn_final, lin_first, y_range, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_timm_model\u001b[39m(arch, n_out, cut\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, n_in\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, init\u001b[39m=\u001b[39mnn\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39mkaiming_normal_, custom_head\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    189\u001b[0m                      concat_pool\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, pool\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, lin_ftrs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ps\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, first_bn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, bn_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, lin_first\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, y_range\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    190\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCreate custom architecture using `arch`, `n_in` and `n_out` from the `timm` library\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 191\u001b[0m     model \u001b[39m=\u001b[39m timm\u001b[39m.\u001b[39;49mcreate_model(arch, pretrained\u001b[39m=\u001b[39;49mpretrained, num_classes\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, in_chans\u001b[39m=\u001b[39;49mn_in, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    192\u001b[0m     body \u001b[39m=\u001b[39m TimmBody(model, pretrained, \u001b[39mNone\u001b[39;00m, n_in)\n\u001b[1;32m    193\u001b[0m     nf \u001b[39m=\u001b[39m body\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnum_features\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/_factory.py:117\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m create_fn \u001b[39m=\u001b[39m model_entrypoint(model_name)\n\u001b[1;32m    116\u001b[0m \u001b[39mwith\u001b[39;00m set_layer_config(scriptable\u001b[39m=\u001b[39mscriptable, exportable\u001b[39m=\u001b[39mexportable, no_jit\u001b[39m=\u001b[39mno_jit):\n\u001b[0;32m--> 117\u001b[0m     model \u001b[39m=\u001b[39m create_fn(\n\u001b[1;32m    118\u001b[0m         pretrained\u001b[39m=\u001b[39;49mpretrained,\n\u001b[1;32m    119\u001b[0m         pretrained_cfg\u001b[39m=\u001b[39;49mpretrained_cfg,\n\u001b[1;32m    120\u001b[0m         pretrained_cfg_overlay\u001b[39m=\u001b[39;49mpretrained_cfg_overlay,\n\u001b[1;32m    121\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    122\u001b[0m     )\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m checkpoint_path:\n\u001b[1;32m    125\u001b[0m     load_checkpoint(model, checkpoint_path)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/hiera.py:849\u001b[0m, in \u001b[0;36mhiera_small_224\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[39m@register_model\u001b[39m\n\u001b[1;32m    847\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhiera_small_224\u001b[39m(pretrained \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    848\u001b[0m     model_args \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(embed_dim\u001b[39m=\u001b[39m\u001b[39m96\u001b[39m, num_heads\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, stages\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m11\u001b[39m, \u001b[39m2\u001b[39m))\n\u001b[0;32m--> 849\u001b[0m     \u001b[39mreturn\u001b[39;00m _create_hiera(\u001b[39m'\u001b[39;49m\u001b[39mhiera_small_224\u001b[39;49m\u001b[39m'\u001b[39;49m, pretrained\u001b[39m=\u001b[39;49mpretrained, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(model_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/hiera.py:830\u001b[0m, in \u001b[0;36m_create_hiera\u001b[0;34m(variant, pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_hiera\u001b[39m(variant: \u001b[39mstr\u001b[39m, pretrained: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Hiera:\n\u001b[1;32m    828\u001b[0m     out_indices \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mout_indices\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m4\u001b[39m)\n\u001b[0;32m--> 830\u001b[0m     \u001b[39mreturn\u001b[39;00m build_model_with_cfg(\n\u001b[1;32m    831\u001b[0m         Hiera,\n\u001b[1;32m    832\u001b[0m         variant,\n\u001b[1;32m    833\u001b[0m         pretrained,\n\u001b[1;32m    834\u001b[0m         \u001b[39m#pretrained_strict=False,\u001b[39;49;00m\n\u001b[1;32m    835\u001b[0m         pretrained_filter_fn\u001b[39m=\u001b[39;49mcheckpoint_filter_fn,\n\u001b[1;32m    836\u001b[0m         feature_cfg\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(out_indices\u001b[39m=\u001b[39;49mout_indices, feature_cls\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgetter\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m    837\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    838\u001b[0m     )\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/_builder.py:410\u001b[0m, in \u001b[0;36mbuild_model_with_cfg\u001b[0;34m(model_cls, variant, pretrained, pretrained_cfg, pretrained_cfg_overlay, model_cfg, feature_cfg, pretrained_strict, pretrained_filter_fn, kwargs_filter, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m num_classes_pretrained \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m features \u001b[39melse\u001b[39;00m \u001b[39mgetattr\u001b[39m(model, \u001b[39m'\u001b[39m\u001b[39mnum_classes\u001b[39m\u001b[39m'\u001b[39m, kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mnum_classes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1000\u001b[39m))\n\u001b[1;32m    409\u001b[0m \u001b[39mif\u001b[39;00m pretrained:\n\u001b[0;32m--> 410\u001b[0m     load_pretrained(\n\u001b[1;32m    411\u001b[0m         model,\n\u001b[1;32m    412\u001b[0m         pretrained_cfg\u001b[39m=\u001b[39;49mpretrained_cfg,\n\u001b[1;32m    413\u001b[0m         num_classes\u001b[39m=\u001b[39;49mnum_classes_pretrained,\n\u001b[1;32m    414\u001b[0m         in_chans\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39min_chans\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m3\u001b[39;49m),\n\u001b[1;32m    415\u001b[0m         filter_fn\u001b[39m=\u001b[39;49mpretrained_filter_fn,\n\u001b[1;32m    416\u001b[0m         strict\u001b[39m=\u001b[39;49mpretrained_strict,\n\u001b[1;32m    417\u001b[0m     )\n\u001b[1;32m    419\u001b[0m \u001b[39m# Wrap the model in a feature extraction module if enabled\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m features:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/timm/models/_builder.py:237\u001b[0m, in \u001b[0;36mload_pretrained\u001b[0;34m(model, pretrained_cfg, num_classes, in_chans, filter_fn, strict)\u001b[0m\n\u001b[1;32m    234\u001b[0m             classifier_bias \u001b[39m=\u001b[39m state_dict[classifier_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.bias\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    235\u001b[0m             state_dict[classifier_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.bias\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m classifier_bias[label_offset:]\n\u001b[0;32m--> 237\u001b[0m load_result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mload_state_dict(state_dict, strict\u001b[39m=\u001b[39;49mstrict)\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m load_result\u001b[39m.\u001b[39mmissing_keys:\n\u001b[1;32m    239\u001b[0m     _logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    240\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMissing keys (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(load_result\u001b[39m.\u001b[39mmissing_keys)\u001b[39m}\u001b[39;00m\u001b[39m) discovered while loading pretrained weights.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    241\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m This is expected if model is being adapted.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Hiera:\n\tsize mismatch for head.projection.weight: copying a param with shape torch.Size([1000, 768]) from checkpoint, the shape in current model is torch.Size([0, 768]).\n\tsize mismatch for head.projection.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([0])."
     ]
    }
   ],
   "source": [
    "learn = vision_learner(dls, \"hiera_small_224\", metrics=accuracy)\n",
    "learn.fine_tune(6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
